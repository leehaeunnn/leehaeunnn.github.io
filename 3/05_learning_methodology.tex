\section{학습 방법론과 최신 기술 습득}

\subsection{특기자전형 준비 과정}
2025년 7월 특기자 전형 준비를 시작했습니다. LLM API 활용 능력과 프로그래밍 실력을 중심으로 포트폴리오를 구성했습니다.

\subsection{Claude Code와의 만남: AI 시대의 프로그래밍}

\paragraph{Claude Code 활용.}
방학이 시작되자마자 Claude Max를 결제했습니다. 한 달 200달러, 학생에게는 큰 금액이었지만 미래를 위한 투자라고 생각했습니다. 

처음 터미널에 ``claude''를 입력했을 때 `command not found' 에러를 만났습니다. WSL 환경 설정, PATH 변수 추가, npm 전역 설치 등 각 단계마다 문제가 발생했지만, 공식 문서를 찾아보고 Stack Overflow를 뒤지며 하나씩 해결해나갔습니다. 특히 Windows 환경에서 심볼릭 링크 권한 문제를 해결하는 데 3시간이 걸렸지만, 드디어 Claude 명령어가 정상 작동하는 것을 확인했을 때 큰 안도감을 느꼈습니다.

Claude Code를 본격적으로 활용하기 시작하면서 코딩 방식이 완전히 바뀌었습니다. 복잡한 알고리즘을 구현할 때 의사코드를 작성하면 Claude가 최적화된 코드로 변환해주었고, 제가 작성한 코드의 버그를 찾아 수정 방향을 제시해주었습니다. 대규모 리팩토링이나 여러 파일을 동시에 수정할 때 Claude의 제안을 받아 작업 효율이 크게 향상되었습니다. 물론 제가 직접 코드를 검토하고 테스트하는 과정은 필수였습니다.

\subsection{바이브코딩 학습}
``바이브코딩 수업 반드시 3일컷 해야함''이라는 목표를 세웠습니다. 새벽까지 강의를 들으며 Cursor와 Claude Code를 동시에 활용하는 방법을 익혔습니다. 개발 생산성이 크게 향상되었고, 이런 방식으로 학습하는 사람이 많지 않을 거라는 확신이 들었습니다.

\paragraph{MCP(Model Context Protocol) 혁신: AI 코딩의 새로운 차원.}
바이브코딩 강의에서 MCP라는 개념을 처음 접했습니다. 단순히 AI와 대화하는 것을 넘어, AI가 파일 시스템, 데이터베이스, 외부 도구들과 직접 소통할 수 있게 하는 프로토콜이었습니다. Claude Code의 MCP 지원 업데이트 소식에 즉시 도입을 결정했습니다.

처음엔 ``MCP가 뭐지? 또 새로운 걸 배워야 하나?''라는 부담감이 있었지만, 실제로 사용해보니 개발 생산성이 획기적으로 향상되었습니다. filesystem MCP로 파일을 직접 읽고 쓰는 것부터, supabase MCP로 데이터베이스를 실시간으로 조작하는 것까지, AI가 실제 개발자처럼 작동하는 것을 확인했습니다.

\paragraph{Serena MCP 도입: 시맨틱 코드 이해의 혁명.}
hansdev.kr 블로그에서 Serena MCP 소개글을 읽고 그 혁신성에 주목했습니다. 일반적인 AI 도구들이 텍스트 수준에서 코드를 분석한다면, Serena는 Language Server Protocol(LSP)을 활용해 코드의 의미와 구조를 정확하게 파악한다는 것이었습니다.

설치 과정은 생각보다 간단했습니다. uv 패키지 매니저를 설치하고, GitHub에서 Serena 레포지토리를 클론한 뒤 Claude Code의 MCP 설정에 추가했습니다. 처음 실행했을 때 ``프로젝트 온보딩을 시작합니다''라는 메시지와 함께 전체 코드베이스를 분석하는 모습은 정말 인상적이었습니다.

Serena의 진가는 대규모 프로젝트에서 발휘되었습니다. 좀비고 게임 프로젝트에서 특정 함수의 모든 참조를 찾아 리팩토링할 때, 기존에는 수십 개 파일을 일일이 검색해야 했지만 Serena는 ``find\_referencing\_symbols'' 명령 하나로 즉시 찾아냈습니다. 심볼 단위로 코드를 수정하니 실수도 줄고, 토큰 사용량도 70\% 이상 절약되었습니다.

특히 Python, TypeScript, Go 등 Tier 1 언어들은 포괄적인 지원을 받았고, ``replace\_symbol\_body'' 기능으로 함수 전체를 한 번에 교체할 수 있어 리팩토링 작업 속도가 현저히 개선되었습니다. AI가 IDE와 유사한 수준으로 작동하게 되었습니다.

\begin{figure}[h]
    \includegraphics[width=\columnwidth]{images/3_kanban.png}
    \caption{프로젝트 관리를 위한 Kanban 보드와 GitHub 연동}
    \label{fig:kanban}
\end{figure}

\subsection{현대적 개발 스택 마스터}

\paragraph{Supabase와 데이터베이스 설계.}
``방학동안 supabase db연동하고 프론트엔드-백엔드 연동하는 거까지 다 해보긴 해야할듯''이라는 목표를 세우고 도전했습니다. GitHub 계정으로 Supabase에 로그인하고, SQL을 직접 작성해 테이블을 생성했습니다. 처음에는 ``supabase 로그인이 갑자기 안돼서''같은 문제들로 고생했지만, 하나씩 해결하며 데이터베이스 구조를 체계적으로 이해하게 되었습니다.

방명록 프로젝트를 통해 Supabase와 GitHub Pages를 연동하는 방법을 익혔습니다. CREATE TABLE부터 시작해 실시간 데이터 동기화까지 구현하며, 백엔드 없이도 풀스택 애플리케이션을 만들 수 있다는 자신감을 얻었습니다.

\paragraph{MCP 생태계 완성: 다양한 도구의 통합.}
바이브코딩 강의를 통해 익힌 MCP 지식을 바탕으로 다양한 MCP 서버들을 프로젝트에 통합했습니다. ``serena-mcp도 설치하고 supabase mcp도 설치''하며 최신 AI 개발 도구들을 적극 도입했습니다. 

처음에는 ``MCP 서버연결 계속 실패''하는 등 어려움이 있었지만, 설정 파일의 경로 문제였다는 것을 발견하고 해결했습니다. Windows WSL 환경에서 특히 주의해야 할 점들을 하나씩 정리하며, MCP 서버 연결에 성공했을 때 큰 성취감을 느꼈습니다.

Serena MCP의 /serena-init 명령어로 프로젝트 구조를 자동으로 분석하니, 수백 개의 파일이 있는 프로젝트도 즉시 파악할 수 있었습니다. 특히 ``get\_symbols\_overview''로 전체 코드의 구조를 한눈에 보고, ``search\_for\_pattern''으로 정규식 기반 검색을 하니 코드 리뷰와 디버깅 속도가 비약적으로 향상되었습니다.

Supabase MCP와 연동해서는 실시간 데이터베이스 조작이 가능해졌고, filesystem MCP로는 복잡한 파일 작업을 자동화했습니다. 이 모든 것이 Claude Code 안에서 통합되어 작동하니, 마치 여러 명의 전문 개발자와 함께 일하는 것 같은 느낌이었습니다.

\paragraph{GitHub과 Vercel을 통한 실전 배포.}
``supabase / vercel 둘다 특기입증자료에 적어야할듯''라는 조언에 따라 실제 배포까지 완성했습니다. GitHub Desktop을 설치하고, commit과 push를 자동화하며 버전 관리의 중요성을 체듍했습니다. Vercel과 연동해 코드를 push하면 자동으로 배포되는 CI/CD 파이프라인을 구축했습니다.

\subsection{학습의 진화: 이론에서 실전으로}
온라인 리소스 활용은 기본이었습니다. Google AI Studio에서 프롬프트를 빌드하고, LeetCode로 알고리즘을 연습했습니다. 가장 큰 성장은 실전 프로젝트를 통해 이루어졌습니다. 

``claude --resume''로 이전 세션을 이어가며 긴 프로젝트도 체계적으로 관리했고, Overleaf에서 LaTeX 문서를 실시간으로 편집하며 협업했습니다. ``Ctrl+S 눌러봐봐 그럼 컴파일 됨''같은 작은 팁들이 모여 전문 개발자 수준의 워크플로우를 구축할 수 있었습니다.

\subsection{Multi-AI 오케스트레이션: 혁신적 문서 작성 워크플로우}

\paragraph{세 AI의 협업 시스템 구축.}
2025년 8월, KAIST 특기자전형 문서를 준비하면서 획기적인 아이디어가 떠올랐습니다. ``왜 하나의 AI만 써야 하지? 각자 잘하는 분야가 다른데...'' Claude는 스토리텔링, GPT-5는 기술 검증, Gemini는 대규모 분석에 강점이 있다는 것을 발견했습니다.

GitHub에서 gemini-gpt-hybrid 프로젝트를 발견하고, 이를 제 상황에 맞게 구현하기로 했습니다. 먼저 Cursor CLI를 설치했습니다. \texttt{curl https://cursor.com/install -fsS | bash} 명령어 한 줄로 설치가 완료되었고, cursor-agent가 정상 작동하는 것을 확인했습니다.

\paragraph{하이브리드 워크플로우 스크립트 개발.}
직접 multi-ai-workflow.sh 스크립트를 작성했습니다. 이 스크립트는 각 AI의 강점을 최대한 활용하도록 설계했습니다:

\begin{itemize}[leftmargin=*]
    \item \textbf{Gemini}: 전체 프로젝트 구조 분석, 216개 노드와 1,847개 엣지의 대규모 그래프 처리
    \item \textbf{GPT-5}: LaTeX 컴파일 최적화, 알고리즘 복잡도 O((V+E)logV) 검증, 기술 용어 일관성 체크
    \item \textbf{Claude}: 입학사정관 관점의 스토리텔링, 성장 과정 서술, 최종 통합
\end{itemize}

특히 자랑스러운 부분은 자동화된 메트릭 추출 시스템입니다. 좀비 게임의 60 FPS 성능, 스마트 그리드의 95\% 수렴률, 교통 라우팅의 75ms 쿼리 시간 등 정량적 지표를 JSON 형태로 자동 수집하도록 구현했습니다.

\paragraph{실전 적용과 성과.}
``./multi-ai-workflow.sh --auto'' 명령으로 전체 워크플로우를 실행하니, 세 AI가 협업하여 문서 품질이 비약적으로 향상되었습니다. Gemini가 찾아낸 구조적 문제를 GPT-5가 기술적으로 검증하고, 제가 Claude를 통해 자연스러운 스토리로 엮어냈습니다.

이 과정에서 ``cursor-agent -p -m gpt-5''로 GPT-5와 직접 대화하며 KAIST 입학에 필요한 구체적인 메트릭을 도출했습니다. SLOC(Source Lines of Code), 테스트 커버리지, 알고리즘 정확도 등 검증 가능한 증거를 체계적으로 정리할 수 있었습니다.

